{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn 14 | Support Vector Machine Classification | SVM | Belajar Machine Learning Dasar\n",
    "\n",
    "Materi Pembelajaran dikutip dari sumber: https://www.youtube.com/watch?v=z69XYXpvVrE\n",
    "\n",
    "Referensi: https://www.svm-tutorial.com/\n",
    "\n",
    "Pada sesi pembelajaran kali ini, kita akan mempelajari salah satu model machine learning yaitu **\"Support Vector Machine\"** atau biasa disingkat sebagai **SVM**.\n",
    "\n",
    "**SVM** termasuk salah satu model machine learning yang cukup umum diterapkan pada **Classification Task**.\n",
    "\n",
    "## Konsep Dasar\n",
    "\n",
    "Ada beberapa konsep dasar yang diharapkan dapat membantu kita memahami mekanisme kerja dari **Support Vector Machine**. Untuk itu, kita akan cermati contoh kasus berikut ini.\n",
    "\n",
    "### Decision Boundary\n",
    "\n",
    "<!-- ![](./images/svm_linear.png) -->\n",
    "<div>\n",
    "    <img src=\"./images/svm_linear.png\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "Semisal saja kita dihadapkan pada sebuah kasus klasifikasi dimana terdapat dua buah class, sebut saja kelas hitam dan putih (bisa dilihat pada gambar terdapat sekumpulan lingkaran berwarna hitam dan putih). Pada kasus ini juga terdapat dua buah feature yaitu $X_1$ dan $X_2$ (bisa diperhatikan pada sumbu $X_1$ dan $X_2$). Disini kita diminta untuk menarik suatu garis lurus atau garis linear yang dapat memisahkan kedua class tersebut. Dalam kasus **Classification Task**, pemisah atau pembatas antar class tersebut juga sering kali dikenal dengan istilah **Decision Boundary**.\n",
    "\n",
    "Semisal saja disini kita dihadapkan pada tiga pilihan garis linear yaitu $H_1, H_2, H_3$. $H_1$ direpresentasikan oleh garis berwarna hijau, $H_2$ direpresentasikan oleh garis berwarna biru, $H_3$ direpresentasikan oleh garis berwarna merah. Pada kali ini, kita diminta untuk memilih ketiga garis tersebut yang paling baik untuk digunakan sebagai **Decision Boundary** atau pemisah antar 2 class yang kita miliki. Kita akan bersama-sama mencermati satu per satu ketiga garis tersebut.\n",
    "\n",
    "+ Pertama-tama kita akan mencermati garis $H_1$ atau garis berwarna hijau. Jika kita perhatikan pada garis tersebut, akan terlihat jelas bahwa garis $H_1$ tersebut tidak bisa digunakan sebagai garis pemisah antar dua class yang kita miliki.\n",
    "+ Berarti disini pilihannya hanya tinggal dua yaitu garis $H_2$ dan $H_3$. Jika kita perhatikan pada keda garis tersebut, kedua garis tersebut dapat memisahkan kedua class yang kita miliki dengan sempurna.\n",
    "+ Yang menjadi pertanyaan berikutnya adalah, manakah dari kedua garis tersebut antara $H_2$ atau $H_3$ yang paling baik dalam memisahkan kedua class kita? dan jawabannya adalah garis $H_3$ dengan alasan karena garis $H_3$ memiliki margin yang lebih besar bila dibandingkan dengan garis $H_2$.\n",
    "\n",
    "## Hyperplane\n",
    "\n",
    "Terminologi pertama yang akan kita pelajari adalah **Hyperplane**. Merupakan terminologi yang umum digunakan dalam dalam **SVM** untuk merepresentasikan **Decision Boundary**. Kita akan menggunakan studi kasus dibawah ini yang sudah kita gunakan sebelumnya.\n",
    "<div>\n",
    "    <img src=\"./images/svm_linear.png\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "Berdasarkan gambar diatas kita dihadapkan pada 2 buah feature, maka kita memiliki plotting dua dimensi, $X_1$ merupakan feature pertama dan $X_2$ merupakan feature kedua dan ketika datanya diplotting, maka kita akan memperoleh plotting dua dimensi. Oleh karenanya, **Decision Boundary** yang kita peroleh berupa suatu garis yang dalam kasus ini berupa garis lurus atau garis linear. Tetapi ketika kita hanya memiliki satu feature saja, maka **Decision Boundary** atau pemisah antara classnya akan berupa titik atau nilai **Threshold**. Lalu ketika terdapat tiga buah feature, maka **Decision Boundary** nya berupa sebuah bidang datar atau juga biasa dikenal dengan istilah **Plane**. Ketika terdapat 4 atau lebih feature, maka pemisah antar classnya berupa bidang multidimensi atau biasa dikenal dengan istilah **Hyperplane**. Pada **SVM**, untuk menyederhanakan istilah, maka setiap **Decision Boundary** yang dihasilkan, umumnya akan disebut sebagai **Hyperplane**.\n",
    "\n",
    "Pada intinya, **SVM** ini mencari **Decision Boundary** yang dapat memisahkan antar class dengan baik.\n",
    "\n",
    "### Maximum Margin\n",
    "\n",
    "Pada kali ini, pertama-tama kita akan memahami terlebih dahulu apa itu **Margin** ?. **Margin** ditentukan berdasarkan jarak terdekat antara **Decision Boundary** dengan anggota dari class yang ingin dipisahkan. Untuk bisa memahaminya dengan lebih baik, kita akan memanfaatkan contoh kasus dibawah ini.\n",
    "\n",
    "<!-- ![](./images/svm_margin.png) -->\n",
    "<div>\n",
    "    <img src=\"./images/svm_margin.png\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "Pada kasus kali ini terdapat dua buah class yaitu kelas **biru** dan kelas **hijau**. Disini juga terdapat dua buah feature yaitu $X_1$ dan $X_2$. Lalu semisal saja disini kita memiliki sebuah **Decision Boundary** berupa garis linear berwarna **merah** (lihat pada gambar) yang digunakan untuk memisahkan kedua class yang kita miliki. Garis linear atau garis lurus berwarna **merah** tersebut merupakan **Decision Boundary** yang memisahkan kelas **biru** dan kelas **hijau** dan area yang diarsir dengan warna **kuning** inilah yang dinamakan dengan **Margin**. Pada gambar tersebut bisa dilihat bahwa terdapat suatu area yang mengapit **Decision Boundary** yang diarsir dengan warna **kuning**, area inilah yang dinamakan **Margin**. **Margin** sendiri diperoleh berdasarkan jarak terdekat antara **Decision Boundary** dengan anggota dari class yang ingin dipisahkan dan setiap anggota class yang berperan untuk menentukan **Margin** dikenal sebagai **Support Vector**. Untuk kasus kita disini, terdapat 3 point sebagai **Support Vector** untuk kasus kita kali ini, dimana **Support Vector** tersebut merupakan anggota dari suatu class yang posisinya paling dekat dengan **Decision Boundary**. Dalam menentukan **Decision Boundary**, **SVM** akan memilih berdasarkan **Margin** terbesar atau juga dikenal dengan istilah **Maximum Margin**.\n",
    "\n",
    "### Linearly Inseperable<br>& Kernel Tricks\n",
    "\n",
    "Referensi: https://www.quora.com/What-is-the-kernel-trick\n",
    "\n",
    "Pada kedua contoh kasus sebelumnya, kita sudah mengenal pemanfaatan dari garis lurus atau linear sebagai **Decision Boundary**. Hanya saja, terdapat beberapa kasus dimana class yang ada tidak bisa dipisahkan dengan memanfaatkan garis linear. Untuk lebih jelasnya, kita akan bersama-sama mempelajari contoh kasus pada gambar dibawah ini.\n",
    "\n",
    "<div>\n",
    "    <img src=\"./images/svm_kernel_01.png\" width=\"800\">\n",
    "</div>    \n",
    "\n",
    "Pada contoh kasus tersebut, juga terdapat 2 buah class yaitu class **titik** dan class **x** (perhatikan pada gambar sisi kiri). Pada gambar tersebut juga terdapat 2 buah feature sehingga ketika dilakukan plotting, kita akan mendapatkan plotting 2 dimensi tersebut. Jika perhatikan pada kasus kali ini (pada gambar sisi kiri), tidaklah memungkinkan bagi kita untuk menarik garis linear sebagai **Decision Boundary**, kondisi tersebut juga dikenal dengan istilah **Linearly Inseperable**. untuk mengatasi semacam tersebut, **SVM** akan memproyeksikan data yang ada ke **Higher Dimention** atau ke dimensi yang lebih tinggi artinya, bila data yang sebelumnya berada dalam 2 dimensi, maka **SVM** akan memproyeksikannya ke 3 dimensi (bisa dilihat pada gambar pada sisi sebelah kanan) yang merupakan hasil proyeksi 3 dimensi dari data sebelumnya yang berbentuk 2 dimensi, dan bisa kita lihat pada gambar tersebut, setelah diproyeksikan ke dimensi yang lebih tinggi, kedua class **titik** dan class **x** tersebut bisa dipisahkan dengan lebih mudah yaitu dengan menerapkan **Decision Boundary** berbentuk bidang datar.\n",
    "\n",
    "Jadi pada gambar sisi sebelah kanan atau tiga dimensi tersebut kita bisa menempatkan suatu bidang datar yang akan berperan sebagai Decision Boundary yang memisahkan antara class **titik** dengan class **x**. Upaya untuk memproyeksikan sekumpulan data ke dimensi yang lebih tinggi tentunya juga akan berdampak pada kenaikan beban komputasi. Untuk menjawab kebutuhan tersebut, **SVM** menawarkan teknik yang sangat efisien yang dikenal dengan istilah **Kernel Tricks**. **SVM** sendiri menawarkan beberapan jenis kernel seperti **Polynomial**, **Sigmoid**, dan **RBF** atau **Radial Basis Function**.\n",
    "\n",
    "Pemanfaatan **SVM** dan **Kernel Tricks** untuk membentuk **Decision Boundary** inilah yang akhirnya menjadikan model machine learning ini diberi nama **Support Vector Machine** yang merupakan beberapa konsep dasar yang perlu diketahui terkait **SVM**.\n",
    "\n",
    "Selanjutnya kita akan mempelajari beberapa pengaplikasian **SVM** dengan memanfaatkan **SKLearn**.\n",
    "\n",
    "## Dataset: The MNIST database of handwritten digits\n",
    "\n",
    "Referensi: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml('mnist_784', data_home='./dataset/mnist', return_X_y=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caranya:\n",
    "\n",
    "+ Pertama-tama kita akan siapkan terlebih dahulu datasetnya. Untuk kasus kita kali ini, kita akan mengadopsi **Handwritten Digits** yang merupakan open dataset yang ditawarkan oleh **MNIST**. Walaupun dataset ini tidak disertakan dalam sebagai sample dataset pada **SKLearn**, tetapi kita bisa mendownloadnya dengan memanfaatkan modul _fetchopenml karena dataset ini juga tersedia pada repositori openml.\n",
    "+ Lalu kita mengimport terlebih dahulu modul _fetchopenml dengan memanggil fungsi \"from sklearn.datasets import fetch_openml\".\n",
    "+ Lalu berikutnya, kita tinggal panggil saja \"fetch_openml\" dan menyebutkan nama datasetnya adalah 'mnist_784', lalu kita juga akan spesifikasikan lokasi pada lokal machine kita untuk mendownload datasetnya yang untuk kasus kita kali ini, kita akan tempatkan pada directory dataset mnist \"data_home='./dataset/mnist/'\".\n",
    "+ Lalu berikutnya, kita akan langsung pisahkan antara feature dengan target labelnya. Oleh karenanya, kita disini sertakan \"return_X_y\" yang diberi nilai True.\n",
    "+ Disini juga kita akan menyertakan variabel X dan y dimana variabel X akan menampung sekumpulan nilai features dan variabel y digunakan untuk menampung sekumpulan nilai target labelnya.\n",
    "+ Lalu berikutnya kita akan tampilkan dimensi data dari featuresnya.\n",
    "\n",
    "**Note : sewaktu kita mengeksekusi script tersebut, pastikan kita memiliki koneksi internet yang baik karena fetch openml ini akan melakukan proses download dataset melalui jaringan internet yang lamanya ditentukan dari kecepatan internet kita masing-masing.**\n",
    "\n",
    "Bisa kita lihat pada hasil output code diatas, dimensi variabel X nya adalah 70000 untuk jumlah barisnya dan 784 untuk jumlah kolomnya, dengan kata lain disini kita bisa menyimpulkan bahwa ukuran dataset kita pada kali ini lumayan besar bila dibandingkan dengan dataset lain yang pernah kita gunakan sebelumnya. Disini terdapat 70000 gambar berbeda yang berisi tulisan tangan manusia yang mencakup angka 0 sampai dengan 9. Dataset ini juga umum digunakan untuk melakukan perbandingan model machine learning dalam mengenali angka atau bilangan dari tulisan tangan manusia.\n",
    "\n",
    "Terdapat salah seorang tokoh besar dalam bidang computer vision yang terlibat dalam pengelolaan dataset ini, namanya adalah \n",
    "**Yann Lecun**. Beliau memiliki konstribusi besar dalam bidang **OCI** atau **Optical Character Recognition** dan juga **Handwritten Recognition**.\n",
    "\n",
    "Selanjutnya kita akan mencoba untuk menampilkan 8 data pertama dari dataset ini. Karena dataset kali ini merupakan data image atau data gambar, maka kita akan menggunakan mathplotlib untuk menampilkan datanya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "pos = 1\n",
    "for data in X[:8]:\n",
    "    plt.subplot(1, 8, pos)\n",
    "    plt.imshow(data.reshape((28, 28)), \n",
    "               cmap=cm.Greys_r)\n",
    "    plt.axis('off')\n",
    "    pos += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caranya:\n",
    "\n",
    "+ Disini pertama-tama kita akan import terlebih dahulu modulnya dengan memanggil method atau fungsi \"import matplotlib.pyplot as plt\" dan juga kita akan mengimport \"import matplotlib.cm as cm\". Dimana cm ini merepresentasikan **Colour Map**.\n",
    "+ Lalu selanjutnya kita akan mencoba melakukan looping terhadap 8 baris pertama dari dataset kita. Oleh karenanya kita memanggil \"for data in X[:8]:\" dimana kita melakukan slishing pada 8 data pertama atau 8 baris pertama dari variabel **X**.\n",
    "+ Untuk selanjutnya kita akan melakukan plotting dengan memanfaatkan pyplot. Datanya juga akan di reshape ke 28 x 28, karena untuk setiap gambarnya terdiri dari 28 x 28 px.\n",
    "+ Bisa kita lihat pada output code diatas, 8 data pertama yang merupakan tulisan tangan manusia atau **Human Handwritten** yang merepresentasikan bilangan atau angka. Bagi kita manusia, tentunya sangat mudah untuk memahami angka-angka pada hasil output code diatas tersebut. Tetapi bagi komputer, ini bukan merupakan hal yang mudah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '0', '4', '1', '9', '2', '1', '3'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bisa dilihat pada code diatas bertujuan untuk menampilkan 8 label yang berkolerasi dengan 8 data pertama tersebut pada code sebelumnya. Dimana data pertama akan diberi label **5**, gambar kedua akan diberi label **0**, gambar ketiga akan diberi label **4**, gambar keempat akan diberi label **1**, gambar kelima akan diberi label **9**, gambar keenam akan diberi label **2**, gambar ketujuh akan diberi label **1**, dan gambar kedelapan akan diberi label **3**.\n",
    "\n",
    "Kita akan melakukan training model kita untuk mempelajari data tersebut. Karena jumlah target labelnya berupa angka atau bilangan, maka jumlah classnya akan ada 10 yaitu mulai dari class 0, 1, 2, 3, sampai dengan 9.\n",
    "\n",
    "Selanjutnya kita akan bagi dataset ini kedalam training dan testing set. Hanya saja kali ini kita tidak akan menggunakan keseluruhan dataset yang ada, hal ini dimaksudkan agar proses training model yang akan kita lakukan dalam kali ini tidak terlalu panjang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X[:60000]\n",
    "# y_train = y[:60000]\n",
    "# X_test = X[60000:]\n",
    "# y_test = y[60000:]\n",
    "\n",
    "X_train = X[:1000]\n",
    "y_train = y[:1000]\n",
    "X_test = X[69000:]\n",
    "y_test = y[69000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Pada code tersebut terdapat dua bagian yaitu ada bagian yang di comment lalu ada juga yang uncomment. Untuk bagian yang di comment tersebut, merupakan bagian yang sebaiknya dicoba pada pc atau komputer kita masing-masing.\n",
    "+ Bisa kita lihat ketika kita mencoba, kita akan menggunakan 60000 data pertama sebagai training set dan 1000 data yang terakhir akan kita gunakan sebagai testing set nya. Hanya saja untuk yang kita lakukan atau demokan kali ini, kita hanya akan menggunakan 1000 data pertama sebagai training set dan 1000 data terakhir sebagai testing set.\n",
    "+ Setelah training set dan testing set nya terbentuk, maka kita akan coba melanjutkan pada tahapan berikutnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification dengan SVC (Support Vector Classifier)\n",
    "\n",
    "Pada kali ini kita akan menerapkan **Support Vector Machine** untuk melakukan klasifikasi angka numerik berdasarkan dataset tulisan tangan yang kita miliki. Pertama-tama, kita akan training modelnya terlebih dahulu yang akan dilakukan pada code berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(random_state=0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caranya:\n",
    "\n",
    "+ Pertama-tama kita akan mengimport modulnya terlebih dahulu dengan memanfaatkan modul SVC atau Support Vector Classifier dengan memanggil method \"from sklearn.svm import SVC\".\n",
    "+ Lalu berikutnya kita akan membentuk objek dari modelnya \"SVC\" dengan menyertakan parameter \"(random_state)\" yang kita beri nilai 0. Lalu objek model yang terbentuk, akan ditampung kedalam variabel \"model\".\n",
    "+ Untuk selanjutnya objek \"model\" tersebut akan kita training dengan method \".fit\" dan menyertakan training set nya yaitu \"(X_train, y_train)\".\n",
    "\n",
    "Setelah modelnya ditraining, selanjutnya kita akan melakukan evaluasi performa dari model yang baru saja kita training tersebut dengan memanfaatkan Classification Report (lihat pada code selanjutnya)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       102\n",
      "           1       0.97      0.99      0.98       119\n",
      "           2       0.85      0.82      0.84        99\n",
      "           3       0.97      0.87      0.92       102\n",
      "           4       0.88      0.95      0.91        92\n",
      "           5       0.91      0.86      0.88        85\n",
      "           6       0.93      0.95      0.94       102\n",
      "           7       0.92      0.94      0.93       115\n",
      "           8       0.89      0.94      0.91        94\n",
      "           9       0.92      0.84      0.88        90\n",
      "\n",
      "    accuracy                           0.92      1000\n",
      "   macro avg       0.92      0.91      0.91      1000\n",
      "weighted avg       0.92      0.92      0.92      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caranya:\n",
    "\n",
    "+ Pertama-tama kita akan mengimport terlebih dahulu Classification Report nya dengan memanggil method \"from sklearn.metrics import classification_report\".\n",
    "+ Lalu berikutnya, kita akan menggunakan testing set nya untuk melakukan prediksi dengan memanggil method \"model.predict(X_test)\" yang hasil prediksinya akan ditampung kedalam variabel \"y_pred\".\n",
    "+ Untuk selanjutnya, hasil prediksi tersebut akan kita bandingkan dengan \"y_test\" nya dengan memanggil method \"(classification_report(y_test, y_pred))\" lalu kita akan print atau cetak hasilnya.\n",
    "\n",
    "Berdasarkan hasil output code diatas, terdapat 10 buah class yaitu class 0 sampai dengan 9 untuk setiap classnya terdapat nilai precission, recall, dan juga f1-score. Lalu pada hasil code tersebut juga kita memiliki nilai precission, recall, f1-score, dan juga accuracy secara keseluruhan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning dengan GridSearchCV\n",
    "\n",
    "Referensi: https://en.wikipedia.org/wiki/Hyperparameter_optimization\n",
    "\n",
    "Sejauh ini dalam pembelajaran mengenai machine learning, kita hampir selalu menggunakan default parameter setiap kali melakukan training model. Padahal untuk tiap model machine learning, terdapat sejumlah parameter yang bisa kita sesuaikan. Dalam konteks machine learning, parameter yang digunakan untuk mengatur proses training dari suatu model, dikenal dengan istilah **Hyperparameter**, dan proses untuk mencari komposisi nilai optimum dari **Hyperparameter** dikenal dengan istilah **Hyperparameter Tuning** atau **Hyperparameter Optimization**.\n",
    "\n",
    "Pada kali ini kita akan melakukan **Hyperparameter Tuning** dengan memanfaatkan modul **GridSearchCV** yang sudah disertakan oleh SkLearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 300 out of 300 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(random_state=0), n_jobs=6,\n",
       "             param_grid={'C': [0.5, 1, 10, 100],\n",
       "                         'gamma': ['scale', 1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['rbf', 'poly', 'sigmoid']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'C': [0.5, 1, 10, 100],\n",
    "    'gamma': ['scale', 1, 0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=SVC(random_state=0),\n",
    "                           param_grid=parameters,\n",
    "                           n_jobs=6,\n",
    "                           verbose=1,\n",
    "                           scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caranya:\n",
    "\n",
    "+ Disini pertama-tama kita akan mengimport terlebih dahulu modulnya dengan memanggil method \"from sklearn.model_selection import GridSearchCV\".\n",
    "+ Lalu berikutnya kita akan spesifikasikan sekumpulan parameter beserta pilihan nilai yang akan kita kombinasikan. Semisal saja disini, kita ingin melakukan parameter tuning untuk tiga parameter yaitu \"kernel\", \"C\", dan \"gamma\" dan ketiganya tersebut merupakan yang bisa ditemui didalam **SVM**.\n",
    "+ Lalu berikutnya, untuk setiap parameter tersebut akan kita tentukan pilihan nilainya. Untuk \"kernel\" disini pilihannya ada \"['rbf', 'poly', 'sigmoid']\", untuk nilai \"C\" disini kita tentukan angkanya yaitu \"[0.5, 1, 10, 100]\", dan untuk \"gamma\" nya kita tentukan pilihannya mulai dari \"['scale', 1, 0.1, 0.01, 0.001]\".\n",
    "+ Pada intinya disini kita akan mencari tahu kombinasi nilai yang paling baik untuk parameter \"kernel\", \"C\", dan \"gamma\" yang bisa kita terapkan terhadap objek **Support Vector Classifier** pada kasus kita. Kita bisa saja mencobanya satu persatu dengan memanfaatkan looping, hanya saja kode program yang dihasilkan tidak akan bersih. Oleh karenanya, disini kita akan mencoba memanfaatkan fasilitas yang sudah ditawarkan oleh SkLearn yang dalam hal ini adalah **GridSearch**.\n",
    "+ Cara menggunakan **GridSearch** pun cukup sederhana. Pertama-tama kita akan membentuk objek dari **GridSearchCv** nya dengan memanggil method \"GridSearchCV\" dengan menyertakan beberapa parameter. Parameter pertama adalah \"(estimator=SVC(random_state=0)\". Lalu berikutnya, kita juga perlu spesifikasikan \"param_grid\" atau parameter grid yang nilainya akan kita asosiasikan dengan \"parameters\" yang baru saja kita spesifikasikan sebelumnya. Selanjutnya yang akan kita atur adalah \"n_jobs\" atau number of jobs yang pada kali ini kita set sebagai 6 yang artinya kita mau menjalankan proses ini secara pararel pada 6 thread dari processor kita (yang kita sesuaikan dengan processor yang kita miliki). Lalu berikutnya, kita juga akan menset parameter \"verbose\" nya dengan nilai 1 bertujuan agar ketika prosesnya berjalan, kita juga mendapatkan feedback yang cukup informatif. Lalu berikutnya kita juga perlu menentukan parameter \"scoring\" yang untuk kasus kita kali ini, kita set nilainya dengan \"accuracy\" artinya nilai pebanding yang kita gunakan adalah accuracy.\n",
    "+ Setelah objek \"GridSearchCV\" nya terbentuk, objeknya akan kita tampung kedalam variabel \"grid_search\".\n",
    "+ Lalu penerapannya juga cukup mudah, disini kita tidak lagi memanggil \"model.fit\" melainkan method fit tersebut akan kita panggil dari objek \"grid_search\" nya \"grid_search.fit(X_train, y_train)\".\n",
    "\n",
    "Bisa kita lihat pada hasil code diatas tersebut bahwa fittingnya akan dilakukan 5 fold atau 5 kali dimana untuk setiap foldnya terdapat 60 candidates, artinya total terdapat 300 proses fitting yang terjadi.\n",
    "\n",
    "Disini kita juga bisa mendapatkan informasi terkait komposisi nilai parameter paling optimum dari hasil pencarian Grid Search ini (perhatikan prosesnya pada code selanjutnya)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.907\n",
      "Best Parameters:\n",
      "\tkernel: rbf\n",
      "\tC: 10\n",
      "\tgamma: scale\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Score: {grid_search.best_score_}')\n",
    "\n",
    "best_params = grid_search.best_estimator_.get_params()\n",
    "print(f'Best Parameters:')\n",
    "for param in parameters:\n",
    "    print(f'\\t{param}: {best_params[param]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caranya:\n",
    "\n",
    "+ Pertama-tama disini kita akan mencoba mengakses terlebih dahulu score terbaiknya atau akurasi terbaiknya dengan cara memanggil method \"grid_search.bestscore\" yang kita sertakan fungsi print untuk melihat hasilnya.\n",
    "+ Pada tahapan berikutnya, kita juga bisa mendapatkan nilai parameter terbaiknya dengan mengakses method \"grid_search.bestestimator.get_params()\". Lalu sekumpulan nilai parameter tersebut akan kita tampung kedalam variabel \"best_params\".\n",
    "+ Untuk selanjutnya akan kita looping dan coba kita tampilkan pada layar.\n",
    "\n",
    "Bisa kita lihat pada output code diatas, bisa terlihat bahwa score accuracy terbaik dari proses Grid Search nya adalah 0.907 dan komposisi nilai parameters terbaik yang berhasil ditemukan adalah **kernelnya** adalah rbf, nilai **C** nya adalah 10, dan nilai parameter **gammanya** adalah scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict & Evaluate\n",
    "\n",
    "Selanjutnya kita akan melakukan evaluasi performa dari model yang baru saja kita training tadi. Disini kita juga akan memanfaatkan Classification Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       102\n",
      "           1       0.98      0.99      0.98       119\n",
      "           2       0.87      0.85      0.86        99\n",
      "           3       0.99      0.89      0.94       102\n",
      "           4       0.91      0.95      0.93        92\n",
      "           5       0.92      0.89      0.90        85\n",
      "           6       0.93      0.94      0.94       102\n",
      "           7       0.93      0.93      0.93       115\n",
      "           8       0.89      0.95      0.92        94\n",
      "           9       0.92      0.88      0.90        90\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.93      0.92      0.92      1000\n",
      "weighted avg       0.93      0.93      0.93      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caranya:\n",
    "\n",
    "+ Untuk melakukan prediksi disini juga agak sedikit berbeda, kita tidak menggunakan \"model.predict\" melainkan kita akan memanfaatkan objek _gridsearch nya dengan memanggil method \"grid_search.predict\" dengan menyertakan nilai dari variabel \"(X_test)\". Lalu hasil prediksinya kita akan tampung kedalam variabel \"y_pred\".\n",
    "+ Untuk selanjutnya nilai \"y_pred\" tersebut kita akan bandingkan dengan nilai \"y_test\" dengan menggunakan \"classification_report\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
